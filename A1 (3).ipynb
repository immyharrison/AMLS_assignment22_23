{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries \n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import mean\n",
    "from numpy import std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import ML methods \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing learning rate graph libraries \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import conusion matrix (plot)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load x train data\n",
    "def import_x():\n",
    "    def get_images(path):\n",
    "        #create array to hold all images information \n",
    "        all_images_as_array = []\n",
    "        for filename in os.listdir(path):\n",
    "            # open file\n",
    "            img = Image.open(path+filename)\n",
    "            #resize \n",
    "            new_img = img.resize((64, 64))\n",
    "            #convert to array\n",
    "            np_array = np.asarray(new_img)\n",
    "            #apprend to one array\n",
    "            all_images_as_array.append(np_array)\n",
    "        # return array with all images \n",
    "        return np.array(all_images_as_array)\n",
    "    #path to image folder\n",
    "    x_train = get_images('Datasets\\\\celeba\\\\img\\\\')\n",
    "    #reshappe and re-process image \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
    "    #create scaler to scale the scale in imput\n",
    "    scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "    #scale the input to normalise the features \n",
    "    x_train_not_split = scaler.transform(x_train)\n",
    "    #retrun normalised array of all images \n",
    "    return x_train_not_split \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import y label train\n",
    "def import_y():\n",
    "    # open csv file with labele s\n",
    "    dataFrame = pd.read_csv('Datasets\\\\celeba\\\\labels.csv',header = None, prefix=\"data\")\n",
    "    #create pandas tabel \n",
    "    dataFrame['data1']= dataFrame['data0'].str.split('\\t')\n",
    "    #seperate into columns \n",
    "    df3 = pd.DataFrame(dataFrame['data1'].to_list(), columns=['image_number','jpg','gender','smiling'])\n",
    "    # separate out geneder information and replace -1 with 0 \n",
    "    df3['gender'] = df3['gender'].replace(['-1'], '0')\n",
    "    # reorder to same os image inputs \n",
    "    df3 = df3.sort_values(by ='image_number')\n",
    "    #remove column heading \n",
    "    df3 = df3.drop(0)\n",
    "    # change to int64 for selected gender column\n",
    "    df3['gender'] = pd.to_numeric(df3['gender'])\n",
    "    y_train_not_split = df3['gender']\n",
    "    #return array with all labels \n",
    "    return y_train_not_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data \n",
    "def split_data(x,y):\n",
    "    #split training input into 80% training 20% validation\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2) \n",
    "    #output the training and validation set \n",
    "    return x_train,x_test,y_train,y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load x test data \n",
    "def import_x_test():\n",
    "    #create array for image output\n",
    "    all_images_as_array = []\n",
    "    #iterate through all images in the test folder\n",
    "    for filename in os.listdir('Datasets\\\\celeba_test\\\\img\\\\'):\n",
    "        #open image in file\n",
    "        img = Image.open('Datasets\\\\celeba_test\\\\img\\\\'+filename)\n",
    "        #resize image to 64x64\n",
    "        new_img = img.resize((64, 64))\n",
    "        #convert image to array\n",
    "        np_array = np.asarray(new_img)\n",
    "        #append array to all image array\n",
    "        all_images_as_array.append(np_array)\n",
    "    x_test_test_data = np.array(all_images_as_array)\n",
    "    # reshape array\n",
    "    x_test_test_data = np.reshape(x_test_test_data, (x_test_test_data.shape[0], -1))\n",
    "    # create scale to normalise the imput\n",
    "    scaler = preprocessing.StandardScaler().fit(x_test_test_data)\n",
    "    #nomalise th earray \n",
    "    x_test_test_data = scaler.transform(x_test_test_data)\n",
    "    #output test s imput\n",
    "    return x_test_test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " # import y label test\n",
    "def import_y_test():   \n",
    "    # open csv file with the labeles \n",
    "    test_dataFrame = pd.read_csv('Datasets\\\\celeba_test\\\\labels.csv',header = None, prefix=\"data\")\n",
    "    # split the tabel into columns for each label type \n",
    "    test_dataFrame['data1']= test_dataFrame['data0'].str.split('\\t')\n",
    "    #name the column \n",
    "    test_df3 = pd.DataFrame(test_dataFrame['data1'].to_list(), columns=['image_number','jpg','gender','smiling'])\n",
    "    # replace -1 with 0\n",
    "    test_df3['gender'] = test_df3['gender'].replace(['-1'], '0')\n",
    "    # sort the label into alphabetical order by image number \n",
    "    test_df3 = test_df3.sort_values(by ='image_number')\n",
    "    #remove the 0th row\n",
    "    test_df3 = test_df3.drop(0)\n",
    "    #conver to numeric and select gender column\n",
    "    test_df3['gender'] = pd.to_numeric(test_df3['gender'])\n",
    "    y_test_test_data = test_df3['gender']\n",
    "    # output y test imput\n",
    "    return y_test_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce the optimised final model \n",
    "def final_model(x_train, y_train):\n",
    "    #load classifier \n",
    "    # make mode with optimised hyperparameters \n",
    "    models = LogisticRegression(C= 0.01)\n",
    "    print('The optimised model used for A1 is:',models)\n",
    "    # Fit the classifier\n",
    "    models.fit(x_train, y_train)\n",
    "    #output final model \n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction on the test data set and confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model with the test data set and produce confusion matrx of results \n",
    "def asses_model(models,x_test_test_data,y_test_test_data):\n",
    "    # Make predictions\n",
    "    predictions = models.predict(x_test_test_data)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy= accuracy_score(predictions, y_test_test_data)\n",
    "    #print the model accuracy as a percentage \n",
    "    print('The model accuracy for A1 is:',accuracy*100,'%')\n",
    "\n",
    "    # plot confusion matrix \n",
    "    plot_confusion_matrix(models, x_test_test_data, y_test_test_data, cmap=plt.cm.Blues)  \n",
    "    #show confusion plot \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final model function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to run the fina model \n",
    "def A1():\n",
    "    #import X vales \n",
    "    x_train_not_split = import_x()\n",
    "    #import y values \n",
    "    y_train_not_split = import_y()\n",
    "    # split training into training and validation data \n",
    "    x_train,x_test,y_train,y_test  = split_data(x_train_not_split,y_train_not_split)\n",
    "    #import y test \n",
    "    y_test_test = import_y_test()\n",
    "    #import x test\n",
    "    x_test_test = import_x_test()\n",
    "    #import fina lmodel for evlaustion \n",
    "    models = final_model(x_train,y_train)\n",
    "    #evaluate final model \n",
    "    asses_model(models,x_test_test,y_test_test)                                        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accuracy for A1 is: 91.3 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "A1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to import y and x and divide into train and validation set \n",
    "def import_X_Y():\n",
    "    # import x\n",
    "    x_train_not_split = import_x()\n",
    "    #imprt y \n",
    "    y_train_not_split = import_y()\n",
    "    #split data into training anad validation \n",
    "    x_train,x_test,y_train,y_test  = split_data(x_train_not_split,y_train_not_split)\n",
    "    #output training and validation \n",
    "    return x_train,x_test,y_train,y_test,x_train_not_split, y_train_not_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run function to inport x/y and create training and validation dataset \n",
    "x_train,x_test,y_train,y_test,x_train_not_split, y_train_not_split = import_X_Y()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation to select the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dicotary to hold CV results \n",
    "CV_df = pd.DataFrame({\"METHOD\":[],\"MEAN\":[],\"STD\":[]})\n",
    "#cross validation - split data into 10 graoups and repate 3 times \n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression \n",
    "# create model\n",
    "model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "#create dicoary of results \n",
    "CV_df_LR = {'Method':'Logistic regression','MEAN':scores.mean(),'STD':scores.std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Decision  tree \n",
    "#create model \n",
    "model = DecisionTreeClassifier()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "#create dicotary of results \n",
    "CV_df_DT = {'Method':'Decision Tree','MEAN':scores.mean(),'STD':scores.std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest  \n",
    "#creat model\n",
    "model = RandomForestClassifier()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "#create dicotary of results \n",
    "CV_df_RF = {'Method':'Random Forest','MEAN':scores.mean(),'STD':scores.std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K nearest Neighbours  \n",
    "#creat model\n",
    "model = KNeighborsClassifier()\n",
    "#evaluate model\n",
    "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "#creaet dictoary of results \n",
    "CV_df_KN = {'Method':'K-Nearest Neighbors','MEAN':scores.mean(),'STD':scores.std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile dictoaries into one pandnas tabel\n",
    "list_of_dict = CV_df_LR, CV_df_DT,CV_df_RF,CV_df_KN\n",
    "# add list to pandas data frame \n",
    "df = pd.DataFrame(list_of_dict)\n",
    "#print table of results \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression model hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make model of ligistic regession (highest accuracy of the CV) \n",
    "models= LogisticRegression()\n",
    "    \n",
    "#Fit the classifier\n",
    "models.fit(x_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the parameter grid based on the results of random search \n",
    "param_grid = { 'C':[100,10,1.0,0.1,0.01]}\n",
    "\n",
    "#Create a based model\n",
    "lr =LogisticRegression()\n",
    "# iterate through all the C values 3 times \n",
    "grid_search = GridSearchCV(estimator = lr, param_grid = param_grid,  cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "#find best parameters \n",
    "grid_search.best_params_\n",
    "best_grid = grid_search.best_estimator_\n",
    "#print best parameter \n",
    "best_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making hyperparameter boxplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of CV into tabel \n",
    "# compile results into pandas table \n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "# sort by best test score \n",
    "results_df = results_df.sort_values(by=[\"rank_test_score\"])\n",
    "# compine results to find averages \n",
    "results_df = results_df.set_index(results_df[\"params\"].apply(lambda x: \"_\".join(str(val) for val in x.values()))).rename_axis(\"kernel\")\n",
    "# add columns for the mean/ standard deviation to table \n",
    "results_df[[\"params\", \"rank_test_score\", \"mean_test_score\", \"std_test_score\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract paramets and test scores \n",
    "r_df = results_df[['param_C','split0_test_score','split1_test_score' , 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot test scores \n",
    "#rotate table \n",
    "df = r_df.set_index('param_C')\n",
    "#plot box plot \n",
    "df.T.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making learning rate plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create data for all the iteration needed for the learning rate graph \n",
    "# create pipeline for optomised model \n",
    "pipeline = make_pipeline(LogisticRegression(C= 0.01))\n",
    "#create parameters to measure and vary #\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipeline, X=x_train_not_split, y=y_train_not_split,cv=10, train_sizes=np.linspace(0.1, 1.0, 10),n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates points for plot \n",
    "#calcuate training plots \n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "#calculates validation set plot points \n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create learning plot \n",
    "#create plot for the training data against training size \n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')\n",
    "#fill with blue to show standard deviation \n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "#creat eplot for valiation data \n",
    "plt.plot(train_sizes, test_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation Accuracy')\n",
    "#fill standard divation in green \n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "#title and axis label the groah \n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Model accuracy')\n",
    "plt.grid()\n",
    "#create legend for colours \n",
    "plt.legend(loc='lower right')\n",
    "#show graph \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
