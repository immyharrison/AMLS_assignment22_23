{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ML methods \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing learning rate graph libraries \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import conusion matrix (plot)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load x train data\n",
    "def import_x():\n",
    "    #size of crop\n",
    "    left = 175\n",
    "    top = 250\n",
    "    right = 320\n",
    "    bottom = 275\n",
    "    #create array for images \n",
    "    all_images_as_array = []\n",
    "    #create array for name of images with sunglasses \n",
    "    remove_array = []\n",
    "    #create array for name of images without sunglasses \n",
    "    keep_array = []\n",
    "    # iterate through all images in the number\n",
    "    for filename in os.listdir('Datasets\\\\cartoon_set\\\\img\\\\'):\n",
    "        #open the file \n",
    "        img = Image.open('Datasets\\\\cartoon_set\\\\img\\\\'+filename)\n",
    "        #crop the file \n",
    "        new_img = img.crop((left, top, right, bottom))\n",
    "        #average the image\n",
    "        average = np.average(new_img)\n",
    "        # if light enough (no 0 pixel for sunglasses) add to array\n",
    "        if average >= 120:\n",
    "            #convert to an array\n",
    "            np_array = np.asarray(new_img)\n",
    "            #normalise \n",
    "            np_array = np_array/255\n",
    "            #append to one large array\n",
    "            all_images_as_array.append(np_array)\n",
    "            #add name to keep images without sunglasses list \n",
    "            keep_array.append(filename)\n",
    "            # if too ow i.e. 0 pixel vlaue for sunglasses then remove \n",
    "        if average <120:\n",
    "            # add name to list of images with sunglasses that is removed \n",
    "            remove_array.append(filename)\n",
    "    # makae array numpy \n",
    "    x_train = np.array(all_images_as_array)\n",
    "    #pre-process\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
    "    #create normalisation \n",
    "    scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "    #normalise the input \n",
    "    x_train_not_split = scaler.transform(x_train)\n",
    "    #print nubmer of images removed because contain sunglasses \n",
    "    print(len(remove_array),'images containing sunglasses were removed from the training dataset')\n",
    "    #output the x values and list of images without sunglasses \n",
    "    return  x_train_not_split,keep_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import y label train\n",
    "def import_y(keep_array):\n",
    "    #read label folders \n",
    "    dataFrame = pd.read_csv('Datasets\\\\cartoon_set\\\\labels.csv',header = None, prefix=\"data\")\n",
    "    #split the labels into columns \n",
    "    dataFrame['data1']= dataFrame['data0'].str.split('\\t')\n",
    "    # label the column names \n",
    "    df3 = pd.DataFrame(dataFrame['data1'].to_list(), columns=['image_number','eye color','face shape','file name'])\n",
    "    #replace the -1 with 0\n",
    "    df3['eye color'] = df3['eye color'].replace(['-1'], '0')\n",
    "    #alphabitise the numbes r\n",
    "    df3 = df3.sort_values(by ='image_number')\n",
    "    #remove row zero\n",
    "    df3 = df3.drop(0)\n",
    "    # make numbers \n",
    "    df3['eye color'] = pd.to_numeric(df3['eye color'])\n",
    "    #select columns \n",
    "    df3_y = df3[['file name','eye color']]\n",
    "\n",
    "    # filter for the same as the non-sunglasses images\n",
    "    df_y = df3_y[df3_y['file name'].isin(keep_array)]\n",
    "    # select the eye colour column \n",
    "    y_train_not_split = df_y['eye color']\n",
    "     #output labels \n",
    "    return y_train_not_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data into training and validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data \n",
    "def split_data(x,y):\n",
    "    #split training input into 80% training 20% validation\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2) \n",
    "    #output the training and validation set \n",
    "    return x_train,x_test,y_train,y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import x test \n",
    "def import_x_test():\n",
    "    #size croped images \n",
    "    left = 175\n",
    "    top = 250\n",
    "    right = 320\n",
    "    bottom = 275\n",
    "    #create array for images that are kept \n",
    "    all_images_as_array_test = []\n",
    "    #create arrray to list the number of array that removed \n",
    "    remove_array_test = []\n",
    "    #create array for images that have sunglasses \n",
    "    keep_array_test = []\n",
    "    #iterate through every file in folder \n",
    "    for filename in os.listdir('Datasets\\\\cartoon_set_test\\\\img\\\\'):\n",
    "        #open file in folder \n",
    "        img = Image.open('Datasets\\\\cartoon_set_test\\\\img\\\\'+filename)\n",
    "        #crop images \n",
    "        new_img = img.crop((left, top, right, bottom))\n",
    "        #average image\n",
    "        average = np.average(new_img)\n",
    "        # if array enough light pixel for no sunglasses add to image array\n",
    "        if average >= 120:\n",
    "            #convert image to array\n",
    "            np_array = np.asarray(new_img)\n",
    "            #normalise \n",
    "            np_array = np_array/255\n",
    "            #append to final array \n",
    "            all_images_as_array_test.append(np_array)\n",
    "            #add name to keep list \n",
    "            keep_array_test.append(filename)\n",
    "            #if array to dark i.e. has sunglasses -  remove \n",
    "        if average <120:\n",
    "            # add number to remove list \n",
    "            remove_array_test.append(filename)\n",
    "    #make array numpy \n",
    "    x_test_test_data = np.array(all_images_as_array_test)\n",
    "    #pre-process results \n",
    "    x_test_test_data = np.reshape(x_test_test_data, (x_test_test_data.shape[0], -1))\n",
    "    #create standardisation \n",
    "    scaler = preprocessing.StandardScaler().fit(x_test_test_data)\n",
    "    #normalise the inputs \n",
    "    x_test_test_data = scaler.transform(x_test_test_data)\n",
    "    #print number of removed sunglasses \n",
    "    print(len(remove_array_test),'number of images containing sunglasses were removed from the testing dataset')\n",
    "    #output the x variable an list of image numbers of images without sunglasses \n",
    "    return x_test_test_data, keep_array_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import y label test\n",
    "def import_y_test(keep_array_test):\n",
    "    #read the csv label file \n",
    "    test_dataFrame = pd.read_csv('Datasets\\\\cartoon_set_test\\\\labels.csv',header = None, prefix=\"data\")\n",
    "    #seperate label into individual column\n",
    "    test_dataFrame['data1']= test_dataFrame['data0'].str.split('\\t')\n",
    "    #label column\n",
    "    test_df3 = pd.DataFrame(test_dataFrame['data1'].to_list(), columns=['image_number','eye color','face shape','file name'])\n",
    "    #replace -1 with 0\n",
    "    test_df3['eye color'] = test_df3['eye color'].replace(['-1'], '0')\n",
    "    #alphabitise by image number so same as order images loaded \n",
    "    test_df3 = test_df3.sort_values(by ='image_number')\n",
    "    #remove row zero\n",
    "    test_df3 = test_df3.drop(0)\n",
    "    #make number \n",
    "    test_df3['eye color'] = pd.to_numeric(test_df3['eye color'])\n",
    "    \n",
    "    # filter for the same as the non-sunglasses images \n",
    "    df_y = test_df3[test_df3['file name'].isin(keep_array_test)]\n",
    "    # select the eye colour column \n",
    "    y_test_test_data = df_y['eye color']\n",
    "    #output labels \n",
    "    return y_test_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create final model \n",
    "def final_model(x_train,y_train):\n",
    "    #load classifier \n",
    "    models = LogisticRegression(C= 0.01)\n",
    "\n",
    "    # Fit the classifier\n",
    "    models.fit(x_train, y_train)\n",
    "    # print the final model \n",
    "    print('The optimised model used for B2 is', models)\n",
    "    #output model \n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate fina lmodel \n",
    "def asses_model(models,x_test_test,y_test_test):\n",
    "    # Make predictions\n",
    "    predictions = models.predict(x_test_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy= accuracy_score(predictions, y_test_test)\n",
    "    #print final model accuracy as percentage \n",
    "    print('This is the accuracy for B2',accuracy*100,'%')\n",
    "\n",
    "    # plot confusion matrix \n",
    "    plot_confusion_matrix(models, x_test_test, y_test_test, cmap=plt.cm.Blues)  \n",
    "    #show graph \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that input training and test data and evaluates \n",
    "def B2():\n",
    "    #import x and array of image numbers that do not have sun glassses \n",
    "    x_train_not_split, keep_array = import_x()\n",
    "    #import y that don't have sunglasses \n",
    "    y_train_not_split = import_y(keep_array)\n",
    "    #split data to training and validation dataset \n",
    "    x_train,x_test,y_train,y_test  = split_data(x_train_not_split,y_train_not_split)\n",
    "    # input x test and the lis that don't have sunglasses \n",
    "    x_test_test,keep_array_test = import_x_test()\n",
    "    #import labels that don't have sunglasses \n",
    "    y_test_test = import_y_test(keep_array_test)\n",
    "    # create final model \n",
    "    models = final_model(x_train,y_train)\n",
    "    #evaluate final model \n",
    "    asses_model(models,x_test_test,y_test_test) \n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run B2 function to prduce model and evaluate \n",
    "B2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import training and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to import y and x and divide into train and validation set \n",
    "def import_X_Y():\n",
    "    #import x and array of image numbers that do not have sun glassses \n",
    "    x_train_not_split, keep_array = import_x()\n",
    "    #import y that don't have sunglasses \n",
    "    y_train_not_split = import_y(keep_array)\n",
    "    #split data to training and validation dataset \n",
    "    x_train,x_test,y_train,y_test  = split_data(x_train_not_split,y_train_not_split)\n",
    "    # putput the training and validation set \n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612 images containing sunglasses were removed from the training dataset\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = import_X_Y()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation for model selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dictoary for the CV results \n",
    "CV_df = pd.DataFrame({\"METHOD\":[],\"MEAN\":[],\"STD\":[]})\n",
    "## create k folds for repeating the model for cross validation \n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression \n",
    "# create model\n",
    "model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "#create dicoary of results \n",
    "CV_df_LR = {'Method':'Logistic regression','MEAN':scores.mean(),'STD':scores.std()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## support vecotr machine \n",
    "#create model \n",
    "model = LinearSVC()\n",
    "## evaluate model\n",
    "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "#create dictionary of results \n",
    "CV_df_SV = {'Method':'Support Vector','MEAN':scores.mean(),'STD':scores.std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Decision  tree \n",
    "#create model \n",
    "model = DecisionTreeClassifier()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "#create dicotary of results \n",
    "CV_df_DT = {'Method':'Decision Tree','MEAN':scores.mean(),'STD':scores.std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest  \n",
    "#creat model\n",
    "model = RandomForestClassifier()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "#create dicotary of results \n",
    "CV_df_RF = {'Method':'Random Forest','MEAN':scores.mean(),'STD':scores.std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K nearest Neighbours  \n",
    "#creat model\n",
    "model = KNeighborsClassifier()\n",
    "#evaluate model\n",
    "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "#creaet dictoary of results \n",
    "CV_df_KN = {'Method':'K-Nearest Neighbors','MEAN':scores.mean(),'STD':scores.std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile dictoaries into one pandnas tabel\n",
    "list_of_dict = CV_df_LR, CV_df_DT,CV_df_RF,CV_df_KN\n",
    "# add list to pandas data frame \n",
    "df = pd.DataFrame(list_of_dict)\n",
    "#print table of results \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create the parameter grid based on the results of random search \n",
    "param_grid = {'C':[100,10,1.0,0.1,0.01]}\n",
    "\n",
    "## Create a based model\n",
    "lr = LogisticRegression()\n",
    "# iterate through all the C values 3 times \n",
    "grid_search = GridSearchCV(estimator = lr, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "#find best parameters \n",
    "grid_search.best_params_\n",
    "best_grid = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print best parameters \n",
    "best_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making hyperparameter boxplot  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of CV into tabel \n",
    "# compile results into pandas table \n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "# sort by best test score \n",
    "results_df = results_df.sort_values(by=[\"rank_test_score\"])\n",
    "# compine results to find averages \n",
    "results_df = results_df.set_index(results_df[\"params\"].apply(lambda x: \"_\".join(str(val) for val in x.values()))).rename_axis(\"kernel\")\n",
    "# add columns for the mean/ standard deviation to table \n",
    "results_df[[\"params\", \"rank_test_score\", \"mean_test_score\", \"std_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract paramets and test scores \n",
    "r_df = results_df[['param_C','split0_test_score','split1_test_score' , 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot test scores \n",
    "#rotate table \n",
    "df = r_df.set_index('param_C')\n",
    "#plot box plot \n",
    "df.T.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Learning rate plot  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create data for all the iteration needed for the learning rate graph \n",
    "# create pipeline for optomised model \n",
    "pipeline = make_pipeline(LogisticRegression(C= 0.01))\n",
    "#create parameters to measure and vary #\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipeline, X=x_train_not_split, y=y_train_not_split,cv=10, train_sizes=np.linspace(0.1, 1.0, 10),n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates points for plot \n",
    "#calcuate training plots \n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "#calculates validation set plot points \n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create learning plot \n",
    "#create plot for the training data against training size \n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')\n",
    "#fill with blue to show standard deviation \n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "#creat eplot for valiation data \n",
    "plt.plot(train_sizes, test_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation Accuracy')\n",
    "#fill standard divation in green \n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "#title and axis label the groah \n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Model accuracy')\n",
    "plt.grid()\n",
    "#create legend for colours \n",
    "plt.legend(loc='lower right')\n",
    "#show graph \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Final Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
